{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 점진적 학습 알고리즘 : 확률적 경사 하강법\n",
    "![](./확률적경사하강법.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 확률적 경사 하강법\n",
    "- 손실 함수 : 어떤 문제에서 머닝러신 알고리즘이 얼마나 엉터리인지 측정하는 기준\n",
    "- 경사 하강법에서 내려오는 산이 손실 함수\n",
    "- 이진 분류에서 사용하는 손실 함수 : 로지스틱 손실 함수 또는 이진 크로스엔트로피 손실 함수\n",
    "- 다중 분류에서 사용하는 손실 함수 : 크로스엔트로피 손실 함수\n",
    "- -log(예측확률) 또는 -log(1-예측확률)을 사용\n",
    "- 손실 함수는 우리가 만들지 않아도 됨\n",
    "- scikit-learn의 LogisticRegression이 로지스틱 회귀를 위한 클래스\n",
    "- predict_proba() 메서드는 예측 확률을 반환\n",
    "  - 이진 분류 : 샘플마다 음성 클래스와 양성 클래스에 대한 확률 반환\n",
    "  - 다중 분류 : 샘플마다 모든 클래스에 대한 확률 반환\n",
    "- decision_function()은 모델이 학습한 선형 방정식의 출력을 반환\n",
    "  - 이진 분류 : 양성 클래스의 선형 방정식\n",
    "  - 다중 분류 : 각 클래스마다 선형 방정식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학교 실습 2 : 확률적 경사 하강법(Stochasitc Gradient Descent)\n",
    "- 훈련한 데이터를 점진적으로 학습하는 방법\n",
    "- fish_csv_data 사용\n",
    "- 사이킷 런의 대표적인 확률적 경사하강법을 제공하는 분류 클래스인 SGDClassifier 사용\n",
    "- 손실 함수 : 어떤 문제에서 머신러닝 알고리즘이 얼마나 엉터리인지를 측정하는 기준\n",
    "- 파일 이름 : StochasticGradientDescent.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fish = pd.read_csv('https://bit.ly/fish_csv_data') #데이타 읽어옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_input = fish[['Weight','Length','Diagonal','Height','Width']].to_numpy()\n",
    "fish_target = fish['Species'].to_numpy() #Species열은 타깃 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(fish_input, fish_target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.transform(train_input)\n",
    "test_scaled = ss.transform(test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확률적 경사 하강법 : SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773109243697479\n",
      "0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joey0\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    }
   ],
   "source": [
    "sc = SGDClassifier(loss='log', max_iter=10, random_state=42) \n",
    "#손실함수는 로지스틱 손실함수, 수행할 에포크 횟수=10\n",
    "sc.fit(train_scaled, train_target)\n",
    "\n",
    "print(sc.score(train_scaled, train_target))  #훈련세트와 테스트 세트의 정확도 출력\n",
    "print(sc.score(test_scaled, test_target))    #warning이 뜬다면 max_iter의 숫자를 늘려준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8151260504201681\n",
      "0.85\n"
     ]
    }
   ],
   "source": [
    "sc.partial_fit(train_scaled, train_target)  \n",
    "#앞의 정확도가 낮으므로 추가로 더 훈련, 이어서 훈련할 때는 partial_fit() 사용, 호출할 때마다 1 에포크씩 이어서 훈련\n",
    "\n",
    "print(sc.score(train_scaled, train_target))   #정확도 출력\n",
    "print(sc.score(test_scaled, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확률적 경사 하강법 : 에포크와 과대/과소 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sc = SGDClassifier(loss = 'log', random_state=42)\n",
    "\n",
    "train_score = [] #train_score와 test_score 점수 기록\n",
    "test_score = []\n",
    "\n",
    "classes = np.unique(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(0,300): #300번의 에포크 동안 훈련\n",
    "  sc.partial_fit(train_scaled, train_target, classes=classes)\n",
    "\n",
    "  train_score.append(sc.score(train_scaled, train_target))\n",
    "  train_score.append(sc.score(test_scaled, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 과대 적합(overfitting) : 모델의 훈련 세트 점수가 테스트 세트 점수보다 훨씬 높을 경우\n",
    "- 과소 적합(underfitting) : 모델의 훈련 세트 점수와 테스트 세트 점수가 동일하게 낮거나 테스트 세트의 성능이 오히려 더 높을 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_score)\n",
    "plt.plot(test_score)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()  \n",
    "#100번 이후에는 훈련세트와 테스트 세트의 간격이 벌어지고있고 정확도 차이가 없다 -> 적합한 반복횟수는 100번정도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확률적 경사 하강법 : 100번 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957983193277311\n",
      "0.925\n"
     ]
    }
   ],
   "source": [
    "sc = SGDClassifier(loss = 'log', max_iter=100, tol=None, random_state=42) \n",
    "#SGDClassifier는 일정 에포크 동안 성능이 향상되지 않으면 더 훈련하지 않고 자동으로 멈춘다.\n",
    "#tol 매개변수에서 향상될 최소값을 지정, tol=None이면 자동으로 멈추지 말라는 의미\n",
    "\n",
    "sc.fit(train_scaled, train_target)                                        \n",
    "\n",
    "print(sc.score(train_scaled, train_target))\n",
    "print(sc.score(test_scaled, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9495798319327731\n",
      "0.925\n"
     ]
    }
   ],
   "source": [
    "sc = SGDClassifier(loss = 'hinge', max_iter=100, tol=None, random_state=42) \n",
    "#손실 함수를 hinge로 바꿔서 적용\n",
    "sc.fit(train_scaled, train_target)\n",
    "\n",
    "print(sc.score(train_scaled, train_target))\n",
    "print(sc.score(test_scaled, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "- 확률적 경사 하강법 : 훈련 세트에서 샘플 하나씩 꺼내 손실 함수의 경사를 따라 최적의 모델을 찾는 알고리즘\n",
    "  - 미니배치 경사 하강법 : 샘플을 하나씩 꺼내지 않고 여러 개 사용하면\n",
    "  - 배치 경사 하강법 : 한 번에 전체 샘플을 사용하면\n",
    "- 손실 함수 : 확률적 경사하강법이 최적화할 대상\n",
    "  - 이진 분류에는 로지스틱 회귀 손실 함수\n",
    "  - 다중 분류에는 크로스 엔트로피 손실함수\n",
    "  - 회귀 문제에는 평균 제곱 오차(MSE) 손실 함수 사용\n",
    "- 에포크 : 확률적 경사 하강법에서 전체 샘플을 모두 사용하는 것을 한 에포크 라고 함"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce8ad003cbacc730e5ae8e25e04f0b81855cad91beef114a29a8b1ddf1550b22"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
